sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
sprintf("precision: %.4f", precision)
tibble(pred = pred_probs, obs = as.numeric(levels(osart_df$heart))[osart_df$heart]) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
confusion[2,2]
confusion[1,2]
pred_probs <- lr_adjusted %>% predict(type = "response")
# 0.111 highest f_score
pred_class  <- ifelse(pred_probs >= 0.05, "positive", "negative")
confusion <- table(osart_df$heart, pred_class)
tp <- confusion[2,2]
fp <- confusion[1,2]
fn <- confusion[2,1]
tn <- confusion[1,1]
recall <- tp / (fn + tp)
precision <- tp /(tp + fp)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
f_score <- (2*precision*recall)/(recall+precision)
confusion
sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
sprintf("precision: %.4f", precision)
tibble(pred = pred_probs, obs = as.numeric(levels(osart_df$heart))[osart_df$heart]) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
pred_probs <- lr_adjusted %>% predict(type = "response")
# 0.111 highest f_score
pred_class  <- ifelse(pred_probs >= 0.05, "positive", "negative")
confusion <- table(osart_df$heart, pred_class)
tp <- confusion[2,2]
fp <- confusion[1,2]
fn <- confusion[2,1]
tn <- confusion[1,1]
recall <- tp / (fn + tp)
precision <- tp /(tp + fp)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
f_score <- (2*precision*recall)/(recall+precision)
confusion
sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
sprintf("false negative rate: %.4f", fn/(fn+tn))
tibble(pred = pred_probs, obs = as.numeric(levels(osart_df$heart))[osart_df$heart]) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
pred_probs <- lr_adjusted %>% predict(type = "response")
# 0.111 highest f_score
pred_class  <- ifelse(pred_probs >= 0.1, "positive", "negative")
confusion <- table(osart_df$heart, pred_class)
tp <- confusion[2,2]
fp <- confusion[1,2]
fn <- confusion[2,1]
tn <- confusion[1,1]
recall <- tp / (fn + tp)
precision <- tp /(tp + fp)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
f_score <- (2*precision*recall)/(recall+precision)
confusion
sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
sprintf("false negative rate: %.4f", fn/(fn+tn))
tibble(pred = pred_probs, obs = as.numeric(levels(osart_df$heart))[osart_df$heart]) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
pred_probs <- lr_adjusted %>% predict(type = "response")
# 0.111 highest f_score
pred_class  <- ifelse(pred_probs >= 0.111, "positive", "negative")
confusion <- table(osart_df$heart, pred_class)
tp <- confusion[2,2]
fp <- confusion[1,2]
fn <- confusion[2,1]
tn <- confusion[1,1]
recall <- tp / (fn + tp)
precision <- tp /(tp + fp)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
f_score <- (2*precision*recall)/(recall+precision)
confusion
sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
sprintf("false negative rate: %.4f", fn/(fn+tn))
tibble(pred = pred_probs, obs = as.numeric(levels(osart_df$heart))[osart_df$heart]) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
pred_probs <- lr_adjusted %>% predict(type = "response")
# 0.111 achieves the highest f_score
pred_class  <- ifelse(pred_probs >= 0.5, "positive", "negative")
confusion <- table(osart_df$heart, pred_class)
tp <- confusion[2,2]
fp <- confusion[1,2]
fn <- confusion[2,1]
tn <- confusion[1,1]
recall <- tp / (fn + tp)
precision <- tp /(tp + fp)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
f_score <- (2*precision*recall)/(recall+precision)
confusion
sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
sprintf("false negative rate: %.4f", fn/(fn+tn))
tibble(pred = pred_probs, obs = as.numeric(levels(osart_df$heart))[osart_df$heart]) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
pred_probs <- lr_adjusted %>% predict(type = "response")
# 0.111 achieves the highest f_score
pred_class  <- ifelse(pred_probs >= 0.01, "positive", "negative")
confusion <- table(osart_df$heart, pred_class)
tp <- confusion[2,2]
fp <- confusion[1,2]
fn <- confusion[2,1]
tn <- confusion[1,1]
recall <- tp / (fn + tp)
precision <- tp /(tp + fp)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
f_score <- (2*precision*recall)/(recall+precision)
confusion
sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
sprintf("false negative rate: %.4f", fn/(fn+tn))
tibble(pred = pred_probs, obs = as.numeric(levels(osart_df$heart))[osart_df$heart]) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
pred_probs <- lr_adjusted %>% predict(type = "response")
# 0.111 achieves the highest f_score
pred_class  <- ifelse(pred_probs >= 0.1, "positive", "negative")
confusion <- table(osart_df$heart, pred_class)
tp <- confusion[2,2]
fp <- confusion[1,2]
fn <- confusion[2,1]
tn <- confusion[1,1]
recall <- tp / (fn + tp)
precision <- tp /(tp + fp)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
f_score <- (2*precision*recall)/(recall+precision)
confusion
sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
sprintf("false negative rate: %.4f", fn/(fn+tn))
tibble(pred = pred_probs, obs = as.numeric(levels(osart_df$heart))[osart_df$heart]) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
pred_probs <- lr_adjusted %>% predict(type = "response")
# 0.111 achieves the highest f_score
pred_class  <- ifelse(pred_probs >= 0.111, "positive", "negative")
confusion <- table(osart_df$heart, pred_class)
tp <- confusion[2,2]
fp <- confusion[1,2]
fn <- confusion[2,1]
tn <- confusion[1,1]
recall <- tp / (fn + tp)
precision <- tp /(tp + fp)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
f_score <- (2*precision*recall)/(recall+precision)
confusion
sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
sprintf("false negative rate: %.4f", fn/(fn+tn))
tibble(pred = pred_probs, obs = as.numeric(levels(osart_df$heart))[osart_df$heart]) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
pred_probs <- lr_adjusted %>% predict(type = "response")
# 0.111 achieves the highest f_score
pred_class  <- ifelse(pred_probs >= 0.111, "positive", "negative")
confusion <- table(osart_df$heart, pred_class)
tp <- confusion[2,2]
fp <- confusion[1,2]
fn <- confusion[2,1]
tn <- confusion[1,1]
recall <- tp / (fn + tp)
precision <- tp /(tp + fp)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
f_score <- (2*precision*recall)/(recall+precision)
confusion
sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
sprintf("false negative rate: %.4f", fn/(tp + tn + fp + fn))
tibble(pred = pred_probs, obs = as.numeric(levels(osart_df$heart))[osart_df$heart]) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
pred_probs <- lr_adjusted %>% predict(type = "response")
# 0.111 achieves the highest f_score
pred_class  <- ifelse(pred_probs >= 0.1, "positive", "negative")
confusion <- table(osart_df$heart, pred_class)
tp <- confusion[2,2]
fp <- confusion[1,2]
fn <- confusion[2,1]
tn <- confusion[1,1]
recall <- tp / (fn + tp)
precision <- tp /(tp + fp)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
f_score <- (2*precision*recall)/(recall+precision)
confusion
sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
sprintf("false negative probability: %.4f", fn/(tp + tn + fp + fn))
tibble(pred = pred_probs, obs = as.numeric(levels(osart_df$heart))[osart_df$heart]) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
pred_probs <- lr_adjusted %>% predict(type = "response")
# 0.111 achieves the highest f_score
pred_class  <- ifelse(pred_probs >= 0.9, "positive", "negative")
confusion <- table(osart_df$heart, pred_class)
tp <- confusion[2,2]
pred_probs <- lr_adjusted %>% predict(type = "response")
# 0.111 achieves the highest f_score
pred_class  <- ifelse(pred_probs >= 0.6, "positive", "negative")
confusion <- table(osart_df$heart, pred_class)
tp <- confusion[2,2]
fp <- confusion[1,2]
fn <- confusion[2,1]
tn <- confusion[1,1]
recall <- tp / (fn + tp)
precision <- tp /(tp + fp)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
f_score <- (2*precision*recall)/(recall+precision)
confusion
sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
sprintf("false negative probability: %.4f", fn/(tp + tn + fp + fn))
tibble(pred = pred_probs, obs = as.numeric(levels(osart_df$heart))[osart_df$heart]) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
pred_probs <- lr_adjusted %>% predict(type = "response")
# 0.111 achieves the highest f_score
pred_class  <- ifelse(pred_probs >= 0.1, "positive", "negative")
confusion <- table(osart_df$heart, pred_class)
tp <- confusion[2,2]
fp <- confusion[1,2]
fn <- confusion[2,1]
tn <- confusion[1,1]
recall <- tp / (fn + tp)
precision <- tp /(tp + fp)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
f_score <- (2*precision*recall)/(recall+precision)
confusion
sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
sprintf("false negative probability: %.4f", fn/(tp + tn + fp + fn))
tibble(pred = pred_probs, obs = as.numeric(levels(osart_df$heart))[osart_df$heart]) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
pred_probs <- lr_adjusted %>% predict(type = "response")
# 0.111 achieves the highest f_score
pred_class  <- ifelse(pred_probs >= 0.9, "positive", "negative")
confusion <- table(osart_df$heart, pred_class)
tp <- confusion[2,2]
pred_probs <- lr_adjusted %>% predict(type = "response")
# 0.111 achieves the highest f_score
pred_class  <- ifelse(pred_probs >= 0.8, "positive", "negative")
confusion <- table(osart_df$heart, pred_class)
tp <- confusion[2,2]
pred_probs <- lr_adjusted %>% predict(type = "response")
# 0.111 achieves the highest f_score
pred_class  <- ifelse(pred_probs >= 0.7, "positive", "negative")
confusion <- table(osart_df$heart, pred_class)
tp <- confusion[2,2]
pred_probs <- lr_adjusted %>% predict(type = "response")
# 0.111 achieves the highest f_score
pred_class  <- ifelse(pred_probs >= 0.5, "positive", "negative")
confusion <- table(osart_df$heart, pred_class)
tp <- confusion[2,2]
fp <- confusion[1,2]
fn <- confusion[2,1]
tn <- confusion[1,1]
recall <- tp / (fn + tp)
precision <- tp /(tp + fp)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
f_score <- (2*precision*recall)/(recall+precision)
confusion
sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
sprintf("false negative probability: %.4f", fn/(tp + tn + fp + fn))
tibble(pred = pred_probs, obs = as.numeric(levels(osart_df$heart))[osart_df$heart]) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
pred_probs <- lr_adjusted %>% predict(type = "response")
# 0.111 achieves the highest f_score
pred_class  <- ifelse(pred_probs >= 0.1, "positive", "negative")
confusion <- table(osart_df$heart, pred_class)
tp <- confusion[2,2]
fp <- confusion[1,2]
fn <- confusion[2,1]
tn <- confusion[1,1]
recall <- tp / (fn + tp)
precision <- tp /(tp + fp)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
f_score <- (2*precision*recall)/(recall+precision)
confusion
sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
sprintf("false negative probability: %.4f", fn/(tp + tn + fp + fn))
tibble(pred = pred_probs, obs = as.numeric(levels(osart_df$heart))[osart_df$heart]) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
pred_probs <- lr_large %>% predict(type = "response")
pred_class  <- ifelse(pred_probs >= 0.7, "positive", "failure")
table(kidney_large$success, pred_class)
tibble(pred = pred_probs, obs = kidney_large$success) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
pred_probs <- lr_small %>% predict(type = "response")
pred_class  <- ifelse(pred_probs >= 0.9, "succ", "fail")
table(kidney_small$success, pred_class)
tibble(pred = pred_probs, obs = kidney_small$success) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
pred_probs <- lr_small %>% predict(type = "response")
pred_class  <- ifelse(pred_probs >= 0.9, "positive", "negative")
table(kidney_small$success, pred_class)
tibble(pred = pred_probs, obs = kidney_small$success) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
pred_probs <- lr_large %>% predict(type = "response")
pred_class  <- ifelse(pred_probs >= 0.7, "positive", "failure")
confusion <- table(kidney_large$success, pred_class)
tp <- confusion[2,2]
fp <- confusion[1,2]
fn <- confusion[2,1]
tn <- confusion[1,1]
recall <- tp / (fn + tp)
precision <- tp /(tp + fp)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
f_score <- (2*precision*recall)/(recall+precision)
confusion
sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
sprintf("false negative probability: %.4f", fn/(tp + tn + fp + fn))
tibble(pred = pred_probs, obs = kidney_large$success) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
pred_probs <- lr_small %>% predict(type = "response")
pred_class  <- ifelse(pred_probs >= 0.9, "positive", "negative")
confusion <- table(kidney_small$success, pred_class)
tp <- confusion[2,2]
fp <- confusion[1,2]
fn <- confusion[2,1]
tn <- confusion[1,1]
recall <- tp / (fn + tp)
precision <- tp /(tp + fp)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
f_score <- (2*precision*recall)/(recall+precision)
confusion
sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
tibble(pred = pred_probs, obs = kidney_small$success) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
pred_probs <- lr_small %>% predict(type = "response")
pred_class  <- ifelse(pred_probs >= 0.8, "positive", "negative")
confusion <- table(kidney_small$success, pred_class)
tp <- confusion[2,2]
pred_probs <- lr_small %>% predict(type = "response")
pred_class  <- ifelse(pred_probs >= 0.88, "positive", "negative")
confusion <- table(kidney_small$success, pred_class)
tp <- confusion[2,2]
fp <- confusion[1,2]
fn <- confusion[2,1]
tn <- confusion[1,1]
recall <- tp / (fn + tp)
precision <- tp /(tp + fp)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
f_score <- (2*precision*recall)/(recall+precision)
confusion
sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
tibble(pred = pred_probs, obs = kidney_small$success) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
pred_probs <- lr_small %>% predict(type = "response")
pred_class  <- ifelse(pred_probs >= 0.9, "positive", "negative")
confusion <- table(kidney_small$success, pred_class)
tp <- confusion[2,2]
fp <- confusion[1,2]
fn <- confusion[2,1]
tn <- confusion[1,1]
recall <- tp / (fn + tp)
precision <- tp /(tp + fp)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
f_score <- (2*precision*recall)/(recall+precision)
confusion
sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
tibble(pred = pred_probs, obs = kidney_small$success) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
pred_probs <- lr_large %>% predict(type = "response")
pred_class  <- ifelse(pred_probs >= 0.8, "positive", "failure")
confusion <- table(kidney_large$success, pred_class)
tp <- confusion[2,2]
pred_probs <- lr_large %>% predict(type = "response")
pred_class  <- ifelse(pred_probs >= 0.75, "positive", "failure")
confusion <- table(kidney_large$success, pred_class)
tp <- confusion[2,2]
pred_probs <- lr_large %>% predict(type = "response")
pred_class  <- ifelse(pred_probs >= 0.6, "positive", "failure")
confusion <- table(kidney_large$success, pred_class)
tp <- confusion[2,2]
pred_probs <- lr_large %>% predict(type = "response")
pred_class  <- ifelse(pred_probs >= 0.71, "positive", "failure")
confusion <- table(kidney_large$success, pred_class)
tp <- confusion[2,2]
fp <- confusion[1,2]
fn <- confusion[2,1]
tn <- confusion[1,1]
recall <- tp / (fn + tp)
precision <- tp /(tp + fp)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
f_score <- (2*precision*recall)/(recall+precision)
confusion
sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
tibble(pred = pred_probs, obs = kidney_large$success) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
pred_probs <- lr_large %>% predict(type = "response")
pred_class  <- ifelse(pred_probs >= 0.70, "positive", "failure")
confusion <- table(kidney_large$success, pred_class)
tp <- confusion[2,2]
fp <- confusion[1,2]
fn <- confusion[2,1]
tn <- confusion[1,1]
recall <- tp / (fn + tp)
precision <- tp /(tp + fp)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
f_score <- (2*precision*recall)/(recall+precision)
confusion
sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
tibble(pred = pred_probs, obs = kidney_large$success) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
# Probit Model for >=2 group
probit_large <- glm(success ~ proc, family = binomial(link = "probit"), data = kidney_large)
tidy(probit_large)
pred_probs <- probit_large %>% predict(type = "response")
pred_class  <- ifelse(pred_probs >= 0.7, "succ", "fail")
table(pred_class, kidney_large$success)
tibble(pred = pred_probs, obs = kidney_large$success) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
# Probit Model for <2 group
probit_small <- glm(success ~ proc, family = binomial(link = "probit"), data = kidney_small)
tidy(probit_small)
pred_probs <- probit_small %>% predict(type = "response")
pred_class  <- ifelse(pred_probs >= 0.9, "succ", "fail")
table(pred_class, kidney_small$success)
tibble(pred = pred_probs, obs = kidney_small$success) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
# Full Probit Model for all patients
probit_full <- glm(success ~ proc + group, family = binomial(link = "probit"), data = kidney_df)
tidy(probit_full)
pred_probs <- probit_full %>% predict(type = "response")
# High True Negative Rate
pred_class  <- ifelse(pred_probs >= 0.7, "succ", "fail")
confusion <- table(pred_class, kidney_df$success)
tp <- confusion[2,2]
fp <- confusion[1,2]
fn <- confusion[2,1]
tn <- confusion[1,1]
recall <- tp / (fn + tp)
precision <- tp /(tp + fp)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
f_score <- (2*precision*recall)/(recall+precision)
confusion
sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
# High True Positive Rate
pred_class  <- ifelse(pred_probs >= 0.9, "succ", "fail")
confusion <- table(pred_class, kidney_df$success)
tp <- confusion[2,2]
fp <- confusion[1,2]
fn <- confusion[2,1]
tn <- confusion[1,1]
recall <- tp / (fn + tp)
precision <- tp /(tp + fp)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
f_score <- (2*precision*recall)/(recall+precision)
confusion
sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
tibble(pred = pred_probs, obs = kidney_df$success) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
# Probit Model for >=2 group
probit_large <- glm(success ~ proc, family = binomial(link = "probit"), data = kidney_large)
tidy(probit_large)
pred_probs <- probit_large %>% predict(type = "response")
pred_class  <- ifelse(pred_probs >= 0.7, "succ", "fail")
table(pred_class, kidney_large$success)
tibble(pred = pred_probs, obs = kidney_large$success) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
# Probit Model for <2 group
probit_small <- glm(success ~ proc, family = binomial(link = "probit"), data = kidney_small)
tidy(probit_small)
pred_probs <- probit_small %>% predict(type = "response")
pred_class  <- ifelse(pred_probs >= 0.9, "succ", "fail")
table(pred_class, kidney_small$success)
tibble(pred = pred_probs, obs = kidney_small$success) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
# Full Probit Model for all patients
probit_full <- glm(success ~ proc + group, family = binomial(link = "probit"), data = kidney_df)
tidy(probit_full)
pred_probs <- probit_full %>% predict(type = "response")
pred_class  <- ifelse(pred_probs >= 0.7, "succ", "fail")
confusion <- table(pred_class, kidney_df$success)
tp <- confusion[2,2]
fp <- confusion[1,2]
fn <- confusion[2,1]
tn <- confusion[1,1]
recall <- tp / (fn + tp)
precision <- tp /(tp + fp)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
f_score <- (2*precision*recall)/(recall+precision)
confusion
sprintf("accuracy: %.4f", accuracy)
sprintf("F-score: %.4f", f_score)
tibble(pred = pred_probs, obs = kidney_df$success) %>%
ggplot(aes(d = obs, m = pred)) + geom_roc() + style_roc(theme = theme_gray)
interaction.plot(x.factor = osart_df$osart,
trace.factor = osart_df$sex,
response = as.numeric(levels(osart_df$heart))[osart_df$heart])
summary(aov(as.numeric(levels(osart_df$heart))[osart_df$heart] ~ osart*sex, data = osart_df))
interaction.plot(x.factor = osart_df$osart,
trace.factor = osart_df$province,
response = as.numeric(levels(osart_df$heart))[osart_df$heart])
summary(aov(as.numeric(levels(osart_df$heart))[osart_df$heart] ~ osart*province, data = osart_df))
lr_prov <- glm(heart ~ osart + province + osart:province, data = osart_df, family = binomial)
tidy(lr_prov)
osart_df <- within(osart_df, sex <- relevel(sex, ref = "FEMALE"))
lr_sex <- glm(heart ~ osart + sex + osart:sex, data = osart_df, family = binomial)
tidy(lr_sex)
# change base references
osart_df <- within(osart_df, heart <- relevel(heart, ref = "0"))
osart_df <- within(osart_df, osart <- relevel(osart, ref = "0"))
osart_df <- within(osart_df, BMI <- relevel(BMI, ref = "healthy"))
osart_df <- within(osart_df, smoker <- relevel(smoker, ref = "NEVER"))
lrmod <- glm(heart ~ osart + age + sex + ethnicity + education + income + BMI + doctor + smoker + drinker + highBP + diabetes + PAI, data = osart_df, family = binomial)
summary(lrmod)
